{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample model using Keras with TF backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the course!\n",
    "\n",
    "This is an introduction lession to help you understand few key starting points using Keras. We are using tensorflow(default) as our backend, but you can use 'theano' or 'CNTK'.\n",
    "\n",
    "**NOTE:**\n",
    "If you are running on the TensorFlow or CNTK backends, your code will automatically run on GPU if any available GPU is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One of the Method:** manually set theano.config.device, theano.config.floatX at the beginning of your code:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import theano\n",
    "theano.config.device = 'gpu'\n",
    "theano.config.floatX = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good to be in the latest version of Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Data\n",
    "\n",
    "1. An experiemental drug was tested on individuals from age 13 to 100.\n",
    "2. The trial had 2100 participants. Half were below 65 years, half were above 65 years old.\n",
    "3. 95% of patients 65 or older experienced side effects.\n",
    "4. 95% of patients under 65 expereinced no side effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    single_list = []\n",
    "    a = randint(0, 1)\n",
    "    b = randint(0, 1)\n",
    "    single_list.append(a)\n",
    "    single_list.append(b)\n",
    "    train_samples.append(single_list)\n",
    "    if a + b == 1: train_labels.append(1)\n",
    "    else: train_labels.append(0)\n",
    "    \n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Display raw data\n",
    "for i in range(500):\n",
    "    print train_samples[i]\n",
    "    print train_labels[i] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data tranformation\n",
    "\n",
    "We cannot fed the raw data to the network, it needs to be transfored to make it normalized and standardized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the model/graph, model.summary() can give you the summary of the architecture output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 08:13:29.618808 139644836800256 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0813 08:13:29.881876 139644836800256 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0813 08:13:29.909465 139644836800256 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0813 08:13:30.110196 139644836800256 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(2,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 786\n",
      "Trainable params: 722\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configures the model for training.\n",
    "\n",
    "Now, that our model/grpah is ready, we can run optimizer and we are going to use Adam.\n",
    "\n",
    "**Optimizers:** Most of the well know optimzers can be found [here](http://ruder.io/optimizing-gradient-descent/).\n",
    "\n",
    "**Loss Function:** Find most of the loss function [here](https://isaacchanghau.github.io/2017/06/07/Loss-Functions-in-Artificial-Neural-Networks/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 08:13:35.222824 139644836800256 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0813 08:13:35.228250 139644836800256 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set\n",
    "\n",
    "Validation set can be given either as a seperate set or let Keras split the validation set from testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_set = [(sample, label), (sample, label), (sample, label)]\n",
    "#model.fit(scaled_train_samples, train_labels, validation_data=valid_set, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To start the training,\n",
    "We have to call fit(), Validation_split will split the training data and put x% of the images into validation set.\n",
    "\n",
    "Let us play a bit! \n",
    "\n",
    "**validation_split**: splits the training data randomly into two parts, trianing and validation based on the percentage specified. DISCLAIMER: this is not recommended practise, avoid doing this on the production network, another important tip, avoid augementing validation data. \n",
    "\n",
    "Play time!!!\n",
    "change validation precentage and see the difference. This will give you intution about how data is fit/overfit/underfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 08:13:41.464354 139644836800256 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.2691 - acc: 0.8917 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1929 - acc: 0.8700 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1499 - acc: 0.8967 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1832 - acc: 0.8950 - val_loss: 8.7062e-04 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1916 - acc: 0.8850 - val_loss: 3.9206e-04 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1839 - acc: 0.8617 - val_loss: 5.3213e-04 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.2376 - acc: 0.8600 - val_loss: 3.3817e-04 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1532 - acc: 0.8800 - val_loss: 2.9538e-04 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1935 - acc: 0.8550 - val_loss: 1.6411e-04 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1928 - acc: 0.8550 - val_loss: 2.1933e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f01373ecc90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_samples, train_labels, validation_split=0.4, batch_size=3, epochs=10, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Play with few hyper parameters:**\n",
    "    1. Batch size\n",
    "    2. Learning Rate (model.optimizer.lr = 0.001)\n",
    "    3. epochs\n",
    "    4. May be also with Optimizers and loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sample_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This save() function save following:\n",
    "\n",
    "    1. The architecture of the model, allowing to create the model.\n",
    "    2. The weights of the model.\n",
    "    3. The training configuration of the model (loss, optimizer).\n",
    "    4. The state of the optimizer, allowing training to resume from where you left before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('sample_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 786\n",
      "Trainable params: 722\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.23024581, -0.19747609,  0.3311491 ,  0.47027552,  0.26918444,\n",
       "         -0.5562627 ,  0.45498133,  0.20552693, -0.03951234, -0.22698158,\n",
       "          0.36985812,  0.08780595, -0.5773784 ,  0.16780013,  0.31996435,\n",
       "          0.45107135],\n",
       "        [ 0.51826805, -0.24160728, -0.38616866, -0.4836536 ,  0.44084105,\n",
       "         -0.39868623, -0.08678935,  0.27585354,  0.5312809 , -0.49114865,\n",
       "          0.5184543 ,  0.17717402,  0.56583714, -0.09748786,  0.48643517,\n",
       "         -0.4718401 ]], dtype=float32),\n",
       " array([-0.00441821,  0.        ,  0.00764048, -0.00321738, -0.03742487,\n",
       "         0.        ,  0.04662776,  0.04820221, -0.00710691,  0.        ,\n",
       "         0.05769783,  0.06134494, -0.00339332,  0.00806597, -0.06309385,\n",
       "        -0.00893059], dtype=float32),\n",
       " array([[-1.27386540e-01,  2.99224854e-01, -1.18940614e-01,\n",
       "         -2.16400370e-01, -4.67129610e-02, -2.06954375e-01,\n",
       "         -3.90084535e-02,  2.05267221e-01, -1.34334877e-01,\n",
       "          5.20245209e-02, -2.47033343e-01, -4.42151949e-02,\n",
       "         -1.40703321e-01, -3.45225662e-01,  3.07062030e-01,\n",
       "          1.99350566e-01,  1.68926939e-01,  9.49776825e-03,\n",
       "         -9.06846374e-02, -2.60289181e-02,  5.32039627e-02,\n",
       "         -1.73843309e-01,  7.40494952e-02, -2.09650934e-01,\n",
       "         -1.20762244e-01,  1.89303786e-01, -1.47749916e-01,\n",
       "         -2.45029509e-01, -2.05276400e-01,  2.31363207e-01,\n",
       "          2.93316662e-01, -3.47490013e-01],\n",
       "        [ 5.27788103e-02,  2.53655165e-01,  2.99344808e-01,\n",
       "         -9.77702439e-02,  1.90796584e-01, -1.70277357e-02,\n",
       "         -1.91011205e-01,  5.49261868e-02, -1.85389519e-02,\n",
       "         -2.43190259e-01,  1.01912260e-01,  2.83672482e-01,\n",
       "          1.43729597e-01, -2.84260690e-01, -1.36677429e-01,\n",
       "          4.48361635e-02,  1.33046061e-01, -2.09341377e-01,\n",
       "          6.06496632e-02, -3.23512554e-01,  1.32925600e-01,\n",
       "         -2.10924402e-01, -3.34337443e-01, -1.71320528e-01,\n",
       "          2.08847731e-01,  3.35305035e-02,  3.19334835e-01,\n",
       "         -1.25012100e-01, -3.49384397e-01, -1.12511814e-02,\n",
       "          1.09354287e-01,  2.94104427e-01],\n",
       "        [ 2.56716102e-01, -1.78567871e-01,  3.12938213e-01,\n",
       "         -1.17003530e-01, -2.57427067e-01,  2.34311834e-01,\n",
       "          3.90953124e-01, -1.69536769e-02,  2.44443774e-01,\n",
       "         -1.97317451e-01,  1.28559425e-01,  1.91702396e-02,\n",
       "          1.48687094e-01,  2.40009725e-01, -3.44456643e-01,\n",
       "          2.82157034e-01,  1.45773590e-01,  1.51844248e-01,\n",
       "          1.65917069e-01,  2.39932477e-01, -6.70996378e-04,\n",
       "         -3.48009199e-01, -3.53420615e-01,  6.78150952e-02,\n",
       "          2.48932853e-01,  2.55180925e-01, -3.05629045e-01,\n",
       "          2.40441278e-01,  3.59141529e-02, -1.50083855e-01,\n",
       "         -2.65460730e-01,  1.55554190e-01],\n",
       "        [ 2.94779211e-01,  2.87169591e-02,  1.63228065e-02,\n",
       "         -1.68795928e-01, -2.29790747e-01, -4.01992425e-02,\n",
       "          1.78757504e-01, -1.80625007e-01,  3.04630339e-01,\n",
       "          1.93381179e-02,  5.44991046e-02, -1.49026915e-01,\n",
       "          1.70068040e-01, -1.52345061e-01, -3.52185428e-01,\n",
       "         -2.76279539e-01,  1.91833138e-01, -4.64457124e-01,\n",
       "         -3.09221745e-01,  1.62965074e-01, -9.91234854e-02,\n",
       "         -2.93210447e-01, -1.02247437e-02,  4.32583958e-01,\n",
       "          5.10624722e-02,  2.96520945e-02, -7.73168057e-02,\n",
       "         -8.52647005e-04, -4.14706290e-01, -5.73660582e-02,\n",
       "          2.04610467e-01,  1.58332661e-01],\n",
       "        [ 2.77288258e-01,  1.61586553e-01,  1.81312501e-01,\n",
       "         -4.50553298e-02,  1.63486540e-01, -8.83035660e-02,\n",
       "         -2.14217395e-01, -2.52054632e-01, -6.66700164e-03,\n",
       "          2.00670108e-01,  2.48315766e-01, -1.53252274e-01,\n",
       "          3.40336740e-01,  1.70857366e-02,  3.51857930e-01,\n",
       "          3.28839749e-01,  6.52223006e-02,  7.48724956e-03,\n",
       "         -1.14344722e-02,  3.81670058e-01,  1.77322298e-01,\n",
       "         -2.03381851e-01, -2.69137062e-02,  2.32205182e-01,\n",
       "         -2.55600270e-02,  1.86499804e-01,  9.72490758e-02,\n",
       "         -1.02249263e-02, -5.25547452e-02, -7.66511681e-03,\n",
       "         -1.64083928e-01, -2.20552891e-01],\n",
       "        [ 2.89566487e-01, -3.52513552e-01,  3.06161672e-01,\n",
       "         -2.21654400e-01, -2.90978462e-01,  2.41517216e-01,\n",
       "          2.48995751e-01,  1.64867908e-01, -1.31527662e-01,\n",
       "         -1.70545280e-01,  2.89484710e-01, -3.49155605e-01,\n",
       "          3.15763026e-01,  2.03875571e-01,  2.11505502e-01,\n",
       "          3.09295207e-01, -1.14399105e-01,  3.76441181e-02,\n",
       "         -2.63940662e-01,  7.48968124e-02,  2.26610452e-01,\n",
       "          6.49784803e-02, -1.20627403e-01, -2.47972071e-01,\n",
       "          1.64581388e-01, -2.47048736e-02, -2.02272758e-01,\n",
       "         -2.15725943e-01, -1.12647817e-01, -1.04748145e-01,\n",
       "          2.61782497e-01,  6.78927600e-02],\n",
       "        [-3.52404982e-01,  2.42182270e-01, -4.51548882e-02,\n",
       "         -2.63938129e-01,  2.79893965e-01,  1.22031517e-01,\n",
       "         -2.65937597e-01,  1.99058473e-01,  4.23620529e-02,\n",
       "         -1.82599984e-02,  8.48124325e-02,  2.80831903e-01,\n",
       "          2.85531431e-01, -1.18417375e-01,  1.34147555e-01,\n",
       "          1.90575927e-01,  2.19988093e-01,  1.23674378e-01,\n",
       "         -2.73363709e-01, -2.32810095e-01,  3.04782707e-02,\n",
       "          2.67766386e-01,  9.24194753e-02, -2.76748016e-02,\n",
       "         -7.43156150e-02, -1.96624801e-01,  7.79357627e-02,\n",
       "          3.65336746e-01, -8.84971917e-02,  6.36307523e-02,\n",
       "         -9.18771699e-02, -5.98571636e-02],\n",
       "        [ 1.40534386e-01,  3.15555722e-01, -1.87122896e-01,\n",
       "         -7.73864985e-02,  3.16189080e-01,  1.80475846e-01,\n",
       "         -9.79611874e-02, -9.42825973e-02, -1.42093211e-01,\n",
       "         -1.57156274e-01,  6.72760829e-02, -6.54476508e-02,\n",
       "          2.67869115e-01,  1.76967382e-01,  4.36741188e-02,\n",
       "          3.25481832e-01,  6.63956702e-02, -4.25980613e-03,\n",
       "          1.23761721e-01,  1.53943151e-01, -2.54212886e-01,\n",
       "          3.07383955e-01,  1.17909223e-01,  1.36767715e-01,\n",
       "         -6.31973222e-02, -4.43067253e-01,  2.18409608e-04,\n",
       "          2.62667358e-01,  2.99820960e-01, -1.35869429e-01,\n",
       "         -1.05817854e-01,  1.11889347e-01],\n",
       "        [-1.94112152e-01, -2.18782485e-01,  1.25121504e-01,\n",
       "         -3.04192930e-01, -1.48836458e-02,  1.76759750e-01,\n",
       "          1.12410299e-01,  2.36286789e-01, -3.11939567e-01,\n",
       "         -6.45180643e-02,  2.78089494e-01,  1.38705522e-01,\n",
       "          1.41646907e-01,  2.09674872e-02, -8.89069289e-02,\n",
       "         -1.74802572e-01,  1.75995603e-01,  1.27072379e-01,\n",
       "          1.09779045e-01,  2.98586935e-01,  2.08251566e-01,\n",
       "         -2.88311750e-01,  1.43660411e-01, -2.90762931e-01,\n",
       "          3.61171246e-01, -1.93022504e-01,  3.37413728e-01,\n",
       "          3.33289176e-01,  4.43723751e-03, -1.35565773e-01,\n",
       "         -1.70163840e-01, -5.43582141e-02],\n",
       "        [-3.48203361e-01, -9.72179472e-02, -7.40448534e-02,\n",
       "         -1.09417096e-01, -1.65074870e-01, -7.41784573e-02,\n",
       "          1.65254086e-01,  1.99819297e-01, -1.35422125e-01,\n",
       "         -3.39890212e-01, -6.73510730e-02, -8.56779814e-02,\n",
       "          1.61401719e-01,  2.61537403e-01, -2.68281788e-01,\n",
       "         -3.22172195e-01,  3.26305181e-01,  6.81319833e-03,\n",
       "          1.34388000e-01, -2.54974008e-01,  1.13069624e-01,\n",
       "         -3.69417071e-02, -5.37454784e-02,  3.39471132e-01,\n",
       "          2.67395377e-03, -2.24022970e-01,  2.77470797e-01,\n",
       "          1.29424125e-01, -1.30186215e-01, -9.74864066e-02,\n",
       "         -3.20380092e-01, -9.67585444e-02],\n",
       "        [-2.13576481e-01,  2.56223649e-01, -4.40318733e-02,\n",
       "          1.87182933e-01, -2.52570421e-01, -2.43638709e-01,\n",
       "          2.31962740e-01,  9.54557061e-02,  3.35383475e-01,\n",
       "         -2.22279519e-01,  3.81260872e-01, -6.30860701e-02,\n",
       "          1.75167605e-01,  1.21589348e-01,  3.22676063e-01,\n",
       "         -1.61303341e-01, -4.06871140e-01,  2.40498781e-01,\n",
       "         -7.84004703e-02,  1.10149406e-01,  2.14975893e-01,\n",
       "         -3.24264094e-02,  1.32478207e-01, -1.28807509e-02,\n",
       "          1.36379562e-02,  1.41976595e-01, -2.52432488e-02,\n",
       "         -1.66920602e-01,  1.48571894e-01,  8.82606506e-02,\n",
       "          1.46383822e-01,  1.12902969e-02],\n",
       "        [-3.61187994e-01,  4.05328989e-01, -3.24441284e-01,\n",
       "         -2.05612645e-01,  1.54590502e-01, -2.61262149e-01,\n",
       "          2.08984450e-01,  1.35406747e-01,  1.60717651e-01,\n",
       "          4.27376516e-02,  2.65764713e-01,  3.51170778e-01,\n",
       "         -5.30753061e-02,  2.31590211e-01, -1.21885657e-01,\n",
       "          3.59702408e-01, -2.31800735e-01,  4.43907129e-03,\n",
       "         -1.25075519e-01,  3.50334018e-01, -2.78772235e-01,\n",
       "          1.85303271e-01,  5.59743047e-02, -1.45045161e-01,\n",
       "          1.93321884e-01,  2.21813574e-01, -2.92999119e-01,\n",
       "         -2.23208100e-01,  3.56028944e-01, -2.60813534e-01,\n",
       "         -1.01409920e-01,  1.48484260e-01],\n",
       "        [ 2.34332412e-01,  1.77600175e-01,  3.32282484e-02,\n",
       "         -3.45387429e-01,  5.43709658e-02, -1.63887843e-01,\n",
       "          3.28960121e-01,  1.86879247e-01,  3.58887345e-01,\n",
       "         -1.32379368e-01, -1.59346059e-01, -2.73790538e-01,\n",
       "          1.21841490e-01, -3.23596537e-01,  1.71493560e-01,\n",
       "         -2.51036078e-01,  3.90426427e-01, -3.37509423e-01,\n",
       "         -1.79346502e-01, -1.04731962e-01,  9.30863321e-02,\n",
       "         -1.00223407e-01, -3.90997082e-01, -1.41600892e-01,\n",
       "         -4.31674756e-02,  6.84517100e-02,  4.58801150e-01,\n",
       "         -2.20969975e-01,  3.38646799e-01, -4.41602081e-01,\n",
       "          4.02480483e-01,  4.28608805e-02],\n",
       "        [-3.03868562e-01, -1.73573177e-02,  1.60914987e-01,\n",
       "         -1.74498320e-01,  1.31997615e-01, -3.54100652e-02,\n",
       "         -3.08200363e-02, -1.60982236e-01, -4.38144952e-02,\n",
       "          2.25428455e-02, -5.52052893e-02, -2.61584789e-01,\n",
       "          2.22114176e-01, -2.09607825e-01,  2.46413331e-02,\n",
       "         -3.10218513e-01, -2.18302846e-01,  1.35586262e-01,\n",
       "         -1.23226464e-01,  8.22445154e-02, -1.40349120e-01,\n",
       "          9.39486176e-02, -3.42126966e-01,  3.92901570e-01,\n",
       "          1.15767084e-01, -1.57523692e-01,  1.42770022e-01,\n",
       "          7.64530003e-02, -4.14385647e-01, -2.04622611e-01,\n",
       "         -2.96779355e-04,  1.98768005e-01],\n",
       "        [ 1.31003439e-01,  7.37641230e-02, -3.42805207e-01,\n",
       "         -1.48355141e-01,  1.32255599e-01,  3.13749880e-01,\n",
       "          1.88636094e-01, -2.16093585e-01, -1.24731712e-01,\n",
       "         -1.77245468e-01,  2.51716733e-01,  1.18584514e-01,\n",
       "          3.13727260e-01,  2.19832599e-01,  3.17931950e-01,\n",
       "          3.32570940e-01,  2.50087708e-01, -2.76741207e-01,\n",
       "          2.27358684e-01, -1.41717270e-01,  3.31968158e-01,\n",
       "         -1.53390154e-01, -2.35253900e-01, -6.64311647e-02,\n",
       "         -1.73639506e-02,  3.62011790e-02,  7.37143382e-02,\n",
       "         -2.19572291e-01, -2.00375482e-01,  1.79281518e-01,\n",
       "          4.95678261e-02, -1.89278692e-01],\n",
       "        [-5.15937209e-02, -1.88094065e-01,  2.69387484e-01,\n",
       "          3.41957599e-01, -2.84152031e-01, -9.62751284e-02,\n",
       "          1.86491802e-01,  4.01097953e-01, -2.43462518e-01,\n",
       "          3.33937526e-01,  1.61765233e-01, -2.92324722e-01,\n",
       "          1.83741421e-01, -6.79138452e-02,  1.80874288e-01,\n",
       "          1.02136068e-01,  7.03573003e-02,  5.38848937e-02,\n",
       "          1.01797894e-01,  2.75397599e-02, -1.02236845e-01,\n",
       "         -8.59048739e-02, -2.30212994e-02,  1.27302989e-01,\n",
       "          2.75968909e-01,  4.19039458e-01, -2.05392852e-01,\n",
       "          2.07918286e-01, -3.44418973e-01, -1.03543676e-01,\n",
       "          3.23280334e-01, -6.10591769e-02]], dtype=float32),\n",
       " array([-0.04540803, -0.00617254, -0.01974362,  0.        ,  0.07637931,\n",
       "        -0.01006809,  0.00369582,  0.00362543,  0.03442551, -0.01860373,\n",
       "         0.00244782,  0.07502252,  0.00642107,  0.09640051,  0.00629374,\n",
       "         0.00370348,  0.05234987,  0.14451697,  0.002176  ,  0.00602561,\n",
       "        -0.02224926,  0.05846733,  0.08147264, -0.00329293,  0.00574385,\n",
       "         0.03568098,  0.01007252, -0.01525394, -0.05016449,  0.23710449,\n",
       "         0.02758234,  0.07802046], dtype=float32),\n",
       " array([0.9724648 , 0.9844893 , 0.97106415, 1.        , 1.0735432 ,\n",
       "        0.9909882 , 1.1870956 , 1.1088538 , 1.2328119 , 0.9854957 ,\n",
       "        0.95752233, 1.4438024 , 0.9843407 , 1.2008519 , 1.0050422 ,\n",
       "        0.9792001 , 1.1336788 , 1.1140592 , 0.9786193 , 0.970481  ,\n",
       "        1.0139011 , 1.2211525 , 1.275028  , 1.2560275 , 1.2102046 ,\n",
       "        1.0431585 , 1.1322016 , 1.1804373 , 1.181955  , 1.0710033 ,\n",
       "        1.3389117 , 0.9700293 ], dtype=float32),\n",
       " array([ 0.00394084, -0.00520631,  0.00388543, -0.0004124 ,  0.0038404 ,\n",
       "         0.00104457, -0.00585327, -0.00542343, -0.00473492,  0.00027565,\n",
       "        -0.00537944,  0.00371007,  0.00485126,  0.00471708,  0.00429427,\n",
       "        -0.00491682, -0.00507354,  0.00295279, -0.00422641,  0.0041695 ,\n",
       "         0.00413685,  0.00509645,  0.00449728, -0.00701868, -0.00503966,\n",
       "        -0.00478985, -0.00518399, -0.00479267, -0.00491574,  0.00427705,\n",
       "        -0.00554185,  0.00439499], dtype=float32),\n",
       " array([2.2846504e-11, 4.7837582e-01, 6.5107229e-03, 0.0000000e+00,\n",
       "        1.6043612e-01, 5.7802668e-15, 1.7511064e-01, 1.0145684e-01,\n",
       "        9.5011473e-02, 2.5888040e-12, 4.5630172e-01, 7.8339212e-02,\n",
       "        5.1548064e-01, 1.0409832e-01, 4.7850856e-01, 3.4039554e-01,\n",
       "        1.3966635e-01, 1.3263786e-01, 1.4112254e-11, 2.8499669e-01,\n",
       "        1.9700913e-01, 2.7573399e-02, 8.1635691e-02, 8.2664877e-02,\n",
       "        9.2260502e-02, 1.2794186e-01, 9.4961062e-02, 5.0952744e-02,\n",
       "        4.5688443e-02, 1.8386297e-01, 1.4701603e-01, 4.1917432e-02],\n",
       "       dtype=float32),\n",
       " array([2.6178057e-12, 1.0652823e-01, 2.4092491e-04, 0.0000000e+00,\n",
       "        1.7618047e-02, 5.0745659e-19, 1.5686240e-02, 3.9080549e-03,\n",
       "        6.4980192e-03, 8.4096033e-14, 8.8649489e-02, 5.8376864e-03,\n",
       "        9.6271217e-02, 5.0499602e-03, 1.5515678e-01, 6.6372134e-02,\n",
       "        1.0197765e-02, 6.9184648e-03, 3.7476161e-13, 3.0501766e-02,\n",
       "        4.4445802e-02, 2.1145744e-03, 7.9268627e-03, 2.1076920e-02,\n",
       "        4.1528894e-03, 7.0758555e-03, 1.7379610e-02, 7.9679377e-03,\n",
       "        6.9849850e-03, 1.3620407e-02, 1.0129492e-02, 1.8162199e-03],\n",
       "       dtype=float32),\n",
       " array([[-0.05218174, -0.18179713],\n",
       "        [-0.18113494,  0.16451685],\n",
       "        [-0.09015715, -0.35791624],\n",
       "        [-0.19381677, -0.16026701],\n",
       "        [ 0.17706531, -0.07237401],\n",
       "        [-0.15514775, -0.2359493 ],\n",
       "        [-0.02064288,  0.2934694 ],\n",
       "        [-0.11406066,  0.4310004 ],\n",
       "        [-0.58562267,  0.5726363 ],\n",
       "        [ 0.34926564,  0.34702027],\n",
       "        [-0.10248876, -0.10872918],\n",
       "        [ 0.33161193, -0.08218157],\n",
       "        [ 0.3068934 , -0.13091224],\n",
       "        [ 0.13918641, -0.56174874],\n",
       "        [ 0.07739221, -0.17816602],\n",
       "        [-0.02015501,  0.05566573],\n",
       "        [ 0.08138015,  0.49713138],\n",
       "        [-0.2187763 , -0.4373105 ],\n",
       "        [ 0.12549824,  0.33301562],\n",
       "        [ 0.25856838,  0.03946098],\n",
       "        [ 0.25524586,  0.01224681],\n",
       "        [ 0.34862307, -0.54252225],\n",
       "        [ 0.12739801, -0.5628935 ],\n",
       "        [-0.525125  ,  0.20700225],\n",
       "        [-0.4641214 ,  0.13125086],\n",
       "        [-0.35574147,  0.426889  ],\n",
       "        [-0.3733994 ,  0.23272642],\n",
       "        [-0.21832776,  0.54184324],\n",
       "        [-0.25400305,  0.32857406],\n",
       "        [ 0.00786785, -0.4194117 ],\n",
       "        [ 0.05291484,  0.40119568],\n",
       "        [ 0.24809311,  0.02788809]], dtype=float32),\n",
       " array([ 0.00504616, -0.00504616], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.summary()\n",
    "new_model.get_weights()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Create a test set and use that to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "\r",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    }
   ],
   "source": [
    "test_samples = []\n",
    "test_labels = []\n",
    "for i in range(100):\n",
    "    single_list = []\n",
    "    a = randint(0, 1)\n",
    "    b = randint(0, 1)\n",
    "    single_list.append(a)\n",
    "    single_list.append(b)\n",
    "    test_samples.append(single_list)\n",
    "    if a + b == 1: test_labels.append(1)\n",
    "    else: test_labels.append(0)\n",
    "\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "for i in range(100):\n",
    "    print test_samples[i]\n",
    "    print test_labels[i] \n",
    "# test_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# scaled_test_samples = test_scaler.fit_transform((test_samples).reshape(-1, 1))\n",
    "\n",
    "predictions = model.predict(test_samples, verbose=1, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.6855370e-05, 9.9995315e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [9.9942338e-01, 5.7666207e-04],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01],\n",
       "       [4.6855370e-05, 9.9995315e-01],\n",
       "       [9.9988616e-01, 1.1386086e-04],\n",
       "       [1.7170099e-04, 9.9982822e-01]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['no-effect', 'effect']\n",
    "cm = confusion_matrix(test_labels, np.round(predictions[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 0 43]\n",
      " [57  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, cm_plot_labels, title='confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

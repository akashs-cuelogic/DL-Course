{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample model using Keras with TF backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the course!\n",
    "\n",
    "This is an introduction lession to help you understand few key starting points using Keras. We are using tensorflow(default) as our backend, but you can use 'theano' or 'CNTK'.\n",
    "\n",
    "**NOTE:**\n",
    "If you are running on the TensorFlow or CNTK backends, your code will automatically run on GPU if any available GPU is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One of the Method:** manually set theano.config.device, theano.config.floatX at the beginning of your code:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import theano\n",
    "theano.config.device = 'gpu'\n",
    "theano.config.floatX = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, BatchNormalization\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good to be in the latest version of Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Data\n",
    "\n",
    "1. An experiemental drug was tested on individuals from age 13 to 100.\n",
    "2. The trial had 2100 participants. Half were below 65 years, half were above 65 years old.\n",
    "3. 95% of patients 65 or older experienced side effects.\n",
    "4. 95% of patients under 65 expereinced no side effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    single_list = []\n",
    "    a = randint(0, 1)\n",
    "    b = randint(0, 1)\n",
    "    single_list.append(a)\n",
    "    single_list.append(b)\n",
    "    train_samples.append(single_list)\n",
    "    if a + b == 1: train_labels.append(1)\n",
    "    else: train_labels.append(0)\n",
    "    \n",
    "    \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[0, 0]\n",
      "0\n",
      "[0, 1]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 1]\n",
      "0\n",
      "[1, 0]\n",
      "1\n",
      "[1, 0]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Display raw data\n",
    "for i in range(500):\n",
    "    print train_samples[i]\n",
    "    print train_labels[i] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data tranformation\n",
    "\n",
    "We cannot fed the raw data to the network, it needs to be transfored to make it normalized and standardized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the model/graph, model.summary() can give you the summary of the architecture output.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0807 12:33:31.884460 140511889401600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0807 12:33:32.186623 140511889401600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0807 12:33:32.214725 140511889401600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0807 12:33:32.428775 140511889401600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(2,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 786\n",
      "Trainable params: 722\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configures the model for training.\n",
    "\n",
    "Now, that our model/grpah is ready, we can run optimizer and we are going to use Adam.\n",
    "\n",
    "**Optimizers:** Most of the well know optimzers can be found [here](http://ruder.io/optimizing-gradient-descent/).\n",
    "\n",
    "**Loss Function:** Find most of the loss function [here](https://isaacchanghau.github.io/2017/06/07/Loss-Functions-in-Artificial-Neural-Networks/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0807 12:33:38.485865 140511889401600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0807 12:33:38.491808 140511889401600 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set\n",
    "\n",
    "Validation set can be given either as a seperate set or let Keras split the validation set from testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_set = [(sample, label), (sample, label), (sample, label)]\n",
    "#model.fit(scaled_train_samples, train_labels, validation_data=valid_set, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To start the training,\n",
    "We have to call fit(), Validation_split will split the training data and put x% of the images into validation set.\n",
    "\n",
    "Let us play a bit! \n",
    "\n",
    "**validation_split**: splits the training data randomly into two parts, trianing and validation based on the percentage specified. DISCLAIMER: this is not recommended practise, avoid doing this on the production network, another important tip, avoid augementing validation data. \n",
    "\n",
    "Play time!!!\n",
    "change validation precentage and see the difference. This will give you intution about how data is fit/overfit/underfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0807 12:33:41.771486 140511889401600 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 600 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.4181 - acc: 0.8133 - val_loss: 0.0620 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.1902 - acc: 0.8800 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.1884 - acc: 0.8783 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.1887 - acc: 0.8717 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.1741 - acc: 0.8683 - val_loss: 9.1821e-04 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1258 - acc: 0.8967 - val_loss: 6.6268e-04 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      " - 0s - loss: 0.1781 - acc: 0.8683 - val_loss: 3.3396e-04 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      " - 0s - loss: 0.1563 - acc: 0.9017 - val_loss: 5.5452e-04 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      " - 0s - loss: 0.1426 - acc: 0.8800 - val_loss: 2.9293e-04 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      " - 0s - loss: 0.1795 - acc: 0.8683 - val_loss: 1.8476e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb17e23e10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_samples, train_labels, validation_split=0.4, batch_size=3, epochs=10, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Play with few hyper parameters:**\n",
    "    1. Batch size\n",
    "    2. Learning Rate (model.optimizer.lr = 0.001)\n",
    "    3. epochs\n",
    "    4. May be also with Optimizers and loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sample_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This save() function save following:\n",
    "\n",
    "    1. The architecture of the model, allowing to create the model.\n",
    "    2. The weights of the model.\n",
    "    3. The training configuration of the model (loss, optimizer).\n",
    "    4. The state of the optimizer, allowing training to resume from where you left before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('sample_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 786\n",
      "Trainable params: 722\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.08187822,  0.57450825, -0.24709019, -0.40695864, -0.26155373,\n",
       "         -0.02546971, -0.04102343, -0.2382024 ,  0.15363933,  0.2823575 ,\n",
       "         -0.41761768,  0.4058545 ,  0.311234  , -0.46097672,  0.4101466 ,\n",
       "          0.28988034],\n",
       "        [ 0.41900143,  0.2561773 , -0.4083675 ,  0.18607801,  0.00976717,\n",
       "          0.32716152, -0.44382766,  0.3616669 , -0.39501166,  0.16790572,\n",
       "         -0.49178046,  0.1753733 ,  0.01778524,  0.51262563, -0.15843481,\n",
       "         -0.4596512 ]], dtype=float32),\n",
       " array([ 0.00324061, -0.02792691,  0.        ,  0.06958386, -0.01589154,\n",
       "         0.08084813,  0.        , -0.02003958,  0.0438495 ,  0.00383254,\n",
       "         0.        , -0.0034278 , -0.0011562 , -0.00011272,  0.00278611,\n",
       "         0.06033959], dtype=float32),\n",
       " array([[ 1.87303081e-01, -3.09215277e-01,  2.85848171e-01,\n",
       "          2.00869575e-01,  6.65544495e-02, -1.77296847e-01,\n",
       "         -7.66408145e-02, -2.51170158e-01,  2.94004738e-01,\n",
       "         -1.39935717e-01,  1.36919487e-02,  1.02176063e-01,\n",
       "         -2.18994413e-02, -2.35547438e-01,  1.45625934e-01,\n",
       "          3.34905207e-01,  2.07939401e-01,  5.85088916e-02,\n",
       "         -4.54557836e-02, -1.54036343e-01,  1.21203974e-01,\n",
       "          1.18678316e-01, -2.05285341e-01, -1.11297397e-02,\n",
       "         -3.64750445e-01, -4.77149002e-02,  1.81547090e-01,\n",
       "         -4.18714620e-02, -3.46314490e-01,  4.35391739e-02,\n",
       "         -3.60622555e-01, -9.07681137e-02],\n",
       "        [ 7.30805844e-02, -3.29833664e-02, -2.42815733e-01,\n",
       "         -2.96419710e-01, -1.20480545e-02,  3.53327185e-01,\n",
       "          3.56560439e-01,  2.59430856e-01, -2.04298750e-01,\n",
       "         -1.38015494e-01,  2.84429163e-01, -6.17849678e-02,\n",
       "          3.04961681e-01,  1.93201333e-01,  1.85761794e-01,\n",
       "         -2.88800508e-01, -2.52499163e-01, -1.12859204e-01,\n",
       "          8.29578936e-02,  2.95535505e-01,  3.09720665e-01,\n",
       "         -3.32918644e-01,  1.96274251e-01,  4.98742647e-02,\n",
       "         -2.45628983e-01, -2.00789824e-01, -2.62794673e-01,\n",
       "         -2.62405396e-01, -1.64841712e-01,  5.23120211e-03,\n",
       "         -2.99135268e-01, -2.54254639e-01],\n",
       "        [ 1.23839647e-01, -3.33217531e-01, -2.23654941e-01,\n",
       "          3.31813693e-02, -7.64184594e-02, -3.32071304e-01,\n",
       "         -1.96938902e-01, -9.97031629e-02, -7.09828734e-03,\n",
       "         -3.08189541e-01,  2.86715478e-01, -2.43922174e-01,\n",
       "         -1.42468482e-01, -4.09382582e-02,  2.73527890e-01,\n",
       "         -1.82904080e-01,  2.14562118e-02,  2.53530473e-01,\n",
       "         -4.69719768e-02, -2.19037250e-01, -3.20730776e-01,\n",
       "         -2.33293772e-02, -2.10430950e-01,  2.52743691e-01,\n",
       "          3.24625701e-01,  2.29807228e-01,  3.42247397e-01,\n",
       "         -1.90289646e-01, -8.78268778e-02,  2.43447691e-01,\n",
       "          1.18457854e-01, -3.17825764e-01],\n",
       "        [ 1.58799902e-01,  1.14517190e-01,  3.01873386e-01,\n",
       "          2.88982719e-01, -3.49596083e-01, -1.18907832e-01,\n",
       "          6.72282130e-02, -3.01316589e-01,  2.92536914e-01,\n",
       "         -8.61607194e-02,  8.03341791e-02,  1.30176544e-01,\n",
       "          4.49233921e-03, -1.46244004e-01, -3.87448311e-01,\n",
       "          3.09249520e-01, -1.50635049e-01,  2.73361653e-01,\n",
       "         -2.04468176e-01,  2.11933423e-02,  3.02606106e-01,\n",
       "          2.71490991e-01, -1.72573909e-01, -6.21690415e-02,\n",
       "          2.82829493e-01,  4.21628237e-01, -1.18690595e-01,\n",
       "          2.65723556e-01, -2.08304554e-01, -1.31438762e-01,\n",
       "         -7.47153684e-02, -2.68334031e-01],\n",
       "        [-1.78271994e-01,  1.89497530e-01, -3.03499520e-01,\n",
       "         -1.93614617e-01, -2.05549836e-01,  3.49356204e-01,\n",
       "         -3.07048917e-01,  3.24339181e-01, -1.24958247e-01,\n",
       "          1.10382080e-01,  9.04370472e-02, -1.06001489e-01,\n",
       "         -1.52566671e-01, -3.13411534e-01,  1.64836138e-01,\n",
       "          1.35232270e-01, -2.82721877e-01, -2.93161660e-01,\n",
       "         -2.48144373e-01,  1.05521202e-01,  5.79358712e-02,\n",
       "          2.49729350e-01,  2.27411330e-01,  1.40555948e-02,\n",
       "          8.39029849e-02, -2.06662267e-01, -1.60232216e-01,\n",
       "         -8.83859098e-02, -3.39421719e-01, -1.63511485e-01,\n",
       "         -2.31026351e-01, -8.40429962e-02],\n",
       "        [-3.25722098e-01,  1.07252598e-01,  4.10194090e-03,\n",
       "         -3.12487502e-02, -3.10507238e-01,  4.05191034e-01,\n",
       "         -1.05332822e-01, -1.62031054e-01,  9.09353122e-02,\n",
       "         -2.24459276e-01,  1.19451553e-01,  2.90657841e-02,\n",
       "          3.07723314e-01, -6.30713999e-02,  1.13291563e-02,\n",
       "          3.35338771e-01,  4.04137149e-02,  1.47295997e-01,\n",
       "          8.02993476e-02,  2.49666154e-01,  1.02781393e-01,\n",
       "          2.11059198e-01,  2.92581260e-01, -1.30521178e-01,\n",
       "         -2.41489112e-01,  2.74758339e-01,  2.26514250e-01,\n",
       "          1.27025649e-01,  2.51400560e-01,  1.19638711e-01,\n",
       "          2.48337254e-01,  3.13033760e-01],\n",
       "        [-1.24151796e-01, -3.24381948e-01, -1.96312264e-01,\n",
       "         -4.14331257e-02, -2.81714588e-01,  1.42818987e-01,\n",
       "         -2.29695857e-01, -2.98074722e-01, -1.22593626e-01,\n",
       "         -2.64641911e-01, -2.21296996e-01, -4.97795641e-02,\n",
       "         -3.31515312e-01,  4.51264679e-02, -2.20530003e-01,\n",
       "         -2.32364684e-01,  1.96301967e-01,  2.55778998e-01,\n",
       "         -2.60585546e-03, -9.04462934e-02,  1.83337837e-01,\n",
       "          2.47984916e-01,  4.47094440e-03,  1.54672533e-01,\n",
       "          1.55177444e-01, -2.10848123e-01, -1.11034781e-01,\n",
       "         -1.01718903e-01, -1.31174058e-01, -3.10490847e-01,\n",
       "          1.21661931e-01, -2.03922883e-01],\n",
       "        [-1.00341998e-01,  4.45116490e-01,  1.90504100e-02,\n",
       "         -1.32011935e-01, -3.78108546e-02, -2.79747099e-01,\n",
       "          9.57482383e-02,  1.10755883e-01,  4.52463686e-01,\n",
       "          1.52848810e-01,  6.51768297e-02,  2.54538924e-01,\n",
       "          6.58854172e-02, -3.37543666e-01,  4.27172147e-02,\n",
       "          2.07906682e-02,  5.65508790e-02,  3.32815051e-01,\n",
       "         -2.25630879e-01, -2.18879223e-01,  2.60799170e-01,\n",
       "          2.03064799e-01,  8.00251439e-02,  2.96508610e-01,\n",
       "          3.17279547e-01, -5.55332866e-04, -8.20312463e-03,\n",
       "         -1.17210805e-01, -1.53363362e-01, -4.16604988e-02,\n",
       "          3.34761947e-01, -3.45438361e-01],\n",
       "        [ 4.69881773e-01,  3.04239094e-01, -3.20725739e-01,\n",
       "          6.45433962e-02,  5.94761252e-01, -6.54795840e-02,\n",
       "         -4.42906141e-01, -7.95519948e-02,  2.63326555e-01,\n",
       "          2.00264782e-01, -1.20570108e-01,  9.21725258e-02,\n",
       "          4.27284747e-01, -3.15125227e-01,  1.46690905e-01,\n",
       "          2.00440109e-01, -2.51943052e-01,  2.52997011e-01,\n",
       "         -2.83301175e-01, -1.41483754e-01,  2.81742275e-01,\n",
       "         -2.16626868e-01, -3.23323846e-01, -4.49399978e-01,\n",
       "          8.70660245e-02,  1.47268936e-01, -2.76029140e-01,\n",
       "         -3.48126054e-01,  1.94778502e-01, -3.69507581e-01,\n",
       "         -2.46383712e-01, -6.15714341e-02],\n",
       "        [-1.57205701e-01,  3.36881906e-01, -2.10572764e-01,\n",
       "          2.62818366e-01, -1.23420551e-01, -1.46251142e-01,\n",
       "         -1.94590256e-01, -2.17440501e-01,  2.73412228e-01,\n",
       "         -3.52148384e-01, -7.87020624e-02, -2.36188039e-01,\n",
       "         -2.81000912e-01,  1.41356647e-01, -2.40142196e-02,\n",
       "         -1.31909430e-01,  1.79076344e-02,  5.89300506e-03,\n",
       "          2.64888704e-02, -3.54834586e-01, -2.26671442e-01,\n",
       "          3.80537822e-03, -2.87590027e-01,  2.51188219e-01,\n",
       "         -1.89756915e-01, -1.14963979e-01,  2.06617609e-01,\n",
       "          2.35622898e-02, -2.00788826e-01,  6.01861775e-02,\n",
       "         -3.62542942e-02,  6.34356495e-03],\n",
       "        [-2.07452342e-01, -2.16813251e-01,  1.64042622e-01,\n",
       "         -2.97494292e-01, -2.61072993e-01,  1.43695384e-01,\n",
       "         -1.45261973e-01,  2.38123387e-01,  2.99256951e-01,\n",
       "         -1.14826888e-01, -2.33756199e-01,  7.23086596e-02,\n",
       "          1.14036977e-01, -1.88078701e-01, -5.59453964e-02,\n",
       "         -1.54040158e-01,  1.00615829e-01, -2.59065986e-01,\n",
       "         -1.36395290e-01, -3.43589783e-01,  9.18781161e-02,\n",
       "          2.88884252e-01, -2.24579230e-01,  7.57504404e-02,\n",
       "         -2.15179294e-01, -2.06452459e-01,  9.69865918e-03,\n",
       "         -2.92520940e-01, -2.30768576e-01, -3.11183155e-01,\n",
       "          1.91788584e-01, -2.42706835e-01],\n",
       "        [ 1.88178271e-01, -2.62415320e-01,  3.55302364e-01,\n",
       "          1.97981313e-01,  2.40835205e-01, -9.77056324e-02,\n",
       "         -2.25446448e-02, -7.67421871e-02, -3.85493077e-02,\n",
       "          1.35768741e-01, -7.44379237e-02,  9.93885323e-02,\n",
       "          8.16744193e-02, -3.26381981e-01, -2.01921966e-02,\n",
       "         -7.69723803e-02,  7.62027949e-02,  7.69370273e-02,\n",
       "         -8.72963965e-02, -6.72278330e-02, -3.06818366e-01,\n",
       "          2.28020698e-02,  3.08627874e-01,  3.19957793e-01,\n",
       "         -1.80379570e-01, -2.06148922e-01, -8.83708745e-02,\n",
       "         -7.99069181e-02,  1.57725438e-01,  2.45260924e-01,\n",
       "          1.46416396e-01,  8.08493569e-02],\n",
       "        [ 3.01416069e-01,  3.27796757e-01,  7.08011389e-02,\n",
       "         -2.57456005e-01,  1.59246698e-01,  1.60614830e-02,\n",
       "          2.04053342e-01, -2.67380804e-01,  6.53732419e-02,\n",
       "         -3.06031048e-01, -8.74715373e-02,  2.45104373e-01,\n",
       "          3.65095675e-01,  3.34858149e-01,  3.28592271e-01,\n",
       "          2.79994428e-01,  2.46636361e-01,  5.02336770e-02,\n",
       "         -2.29015946e-02, -1.05843149e-01, -2.49423131e-01,\n",
       "         -1.54525489e-01,  1.35806158e-01, -2.31384918e-01,\n",
       "         -7.41802379e-02, -2.32844368e-01,  2.29377732e-01,\n",
       "         -1.24794945e-01, -1.27907336e-01,  1.19279951e-01,\n",
       "         -5.16732000e-02, -3.49438041e-01],\n",
       "        [ 3.82587671e-01,  2.27433264e-01,  1.59655571e-01,\n",
       "         -3.35131645e-01, -3.99377346e-01, -3.28110486e-01,\n",
       "          1.56405687e-01,  3.17241579e-01,  3.02160412e-01,\n",
       "          1.61121756e-01, -4.98481870e-01, -3.21594626e-02,\n",
       "         -1.36594206e-01, -9.66272950e-02,  1.29104301e-01,\n",
       "          1.45956576e-01, -2.48566270e-01, -5.80685064e-02,\n",
       "         -2.15866804e-01, -2.24544063e-01,  3.78963858e-01,\n",
       "         -3.66825521e-01, -1.37167111e-01, -2.45951220e-01,\n",
       "          1.61749497e-01, -2.97100097e-01,  2.52883226e-01,\n",
       "         -7.40297437e-02, -3.16343963e-01,  2.23608762e-02,\n",
       "         -3.03948402e-01, -2.31351316e-01],\n",
       "        [-1.24787182e-01,  1.11317925e-01, -1.78789392e-01,\n",
       "         -6.36098161e-02, -7.46522471e-02, -3.26939493e-01,\n",
       "          2.35647261e-01, -4.76729870e-02, -1.90411329e-01,\n",
       "          4.85574603e-02, -1.87830254e-01,  3.86281461e-01,\n",
       "          4.32940394e-01, -2.34354004e-01, -2.61511505e-01,\n",
       "          2.45515004e-01, -6.82725310e-02,  2.63395488e-01,\n",
       "         -1.83316961e-01, -2.12302223e-01, -1.07982658e-01,\n",
       "         -1.15173504e-01, -1.80627704e-01, -1.12457246e-01,\n",
       "          2.13281676e-01,  2.33319700e-01, -3.61981213e-01,\n",
       "          1.22237906e-01, -1.29448578e-01,  1.77778706e-01,\n",
       "         -2.46131718e-01,  1.36948571e-01],\n",
       "        [ 2.75749594e-01, -7.29434937e-02,  1.16114102e-01,\n",
       "         -3.18890363e-01,  3.97894233e-01, -3.68728340e-01,\n",
       "         -2.16913983e-01,  3.07252109e-02, -2.97192544e-01,\n",
       "         -2.16983020e-01, -2.50424773e-01,  2.14025214e-01,\n",
       "         -5.31668216e-03, -9.91916656e-03, -1.86795518e-02,\n",
       "         -2.46212259e-01,  6.23807907e-02,  4.69597995e-01,\n",
       "          3.03773552e-01, -1.25477582e-01, -9.37644467e-02,\n",
       "         -1.87200308e-02, -2.96398282e-01, -7.42935091e-02,\n",
       "         -1.73696019e-02,  2.86352992e-01, -2.87219226e-01,\n",
       "         -1.11968718e-01, -5.92967160e-02, -3.19424123e-01,\n",
       "          2.72102118e-01,  5.20502888e-02]], dtype=float32),\n",
       " array([ 0.01240278,  0.01131382, -0.02658565, -0.00584498, -0.01321307,\n",
       "         0.13207386, -0.13038327, -0.01572605, -0.00735937,  0.        ,\n",
       "         0.10646702, -0.00868193, -0.00612417,  0.        , -0.10466249,\n",
       "         0.07885507,  0.0798474 , -0.02286325,  0.        ,  0.13947417,\n",
       "        -0.03986653, -0.04871193, -0.03410827, -0.01767827, -0.00861356,\n",
       "         0.05359207,  0.00587221, -0.01369226, -0.02476024, -0.11289918,\n",
       "        -0.03267086, -0.00980991], dtype=float32),\n",
       " array([1.4959884 , 1.2506585 , 1.1858542 , 0.99440515, 1.2759565 ,\n",
       "        1.611655  , 1.0170672 , 0.98716444, 1.1837317 , 1.        ,\n",
       "        1.1404995 , 1.0559894 , 1.0343516 , 1.        , 0.97734845,\n",
       "        0.9447402 , 1.038099  , 1.1853718 , 1.        , 1.4530056 ,\n",
       "        1.2953575 , 0.97519475, 1.1155251 , 1.1541334 , 0.9935588 ,\n",
       "        1.2578049 , 1.1961514 , 0.98891985, 0.9678325 , 1.0365312 ,\n",
       "        0.95201087, 0.9855045 ], dtype=float32),\n",
       " array([-5.7024746e-03, -3.8686898e-02, -4.3213973e-04, -2.5290567e-05,\n",
       "        -1.8598455e-03, -4.1236323e-03, -1.6378947e-03, -3.5747429e-04,\n",
       "        -9.7543234e-04,  1.7741544e-05, -3.0931754e-03, -2.1468818e-03,\n",
       "        -4.5172046e-03,  6.5968186e-04, -3.4232957e-03, -9.0485968e-04,\n",
       "        -2.3258072e-03, -1.8973014e-04,  5.1012763e-04,  1.6645953e-03,\n",
       "        -6.3904291e-03, -1.1114691e-03, -2.5496308e-03, -1.7166127e-03,\n",
       "        -5.3260778e-04,  4.9190334e-04, -6.3069817e-04, -3.0269937e-04,\n",
       "        -3.3692500e-04, -1.6749786e-03, -4.3798907e-04,  6.2609033e-08],\n",
       "       dtype=float32),\n",
       " array([1.5784618e-01, 1.3917811e-01, 5.7341542e-02, 6.6626562e-08,\n",
       "        7.0425779e-02, 9.8947339e-02, 3.3717740e-02, 2.2665869e-12,\n",
       "        1.6459604e-01, 0.0000000e+00, 7.7862963e-02, 1.3569129e-01,\n",
       "        2.8192765e-01, 0.0000000e+00, 3.2790203e-02, 1.7727940e-01,\n",
       "        3.4742933e-02, 1.6805260e-01, 0.0000000e+00, 5.9296932e-02,\n",
       "        9.6174277e-02, 9.0907214e-08, 5.3753011e-02, 4.6338778e-02,\n",
       "        4.1629315e-15, 3.2924384e-02, 5.8368374e-02, 2.5799263e-09,\n",
       "        5.8798442e-08, 5.1679421e-02, 2.0688459e-07, 5.5716598e-10],\n",
       "       dtype=float32),\n",
       " array([9.0708630e-03, 5.5348142e-03, 1.0210521e-02, 7.4313437e-12,\n",
       "        1.5856551e-02, 1.0680209e-02, 2.9706869e-03, 6.0481588e-14,\n",
       "        4.8999298e-02, 0.0000000e+00, 6.7042750e-03, 8.0777854e-03,\n",
       "        4.4787183e-02, 0.0000000e+00, 2.7596205e-03, 2.2550710e-02,\n",
       "        1.0969948e-03, 8.3758114e-03, 0.0000000e+00, 3.7357430e-03,\n",
       "        2.8706707e-02, 9.7299451e-12, 7.5363955e-03, 5.6115203e-03,\n",
       "        1.3029144e-18, 3.2519610e-03, 1.0573143e-02, 6.4682268e-14,\n",
       "        8.2822516e-12, 6.9796126e-03, 6.8670743e-11, 1.3727700e-12],\n",
       "       dtype=float32),\n",
       " array([[-1.3806148e-01,  3.7282339e-01],\n",
       "        [-6.8352669e-02,  1.4457634e-01],\n",
       "        [-3.3042383e-01,  3.8478673e-01],\n",
       "        [ 2.7583364e-02,  2.8111108e-02],\n",
       "        [-5.7034844e-01, -5.6406472e-02],\n",
       "        [ 3.9800295e-01, -7.0960671e-01],\n",
       "        [ 3.7087068e-01, -3.1469223e-01],\n",
       "        [ 2.3427498e-01, -2.9937527e-01],\n",
       "        [-5.4618466e-01, -2.0125027e-04],\n",
       "        [ 1.3634810e-01,  1.3601072e-01],\n",
       "        [ 8.7570257e-02, -3.3082795e-01],\n",
       "        [-1.5960327e-01,  1.1426994e-01],\n",
       "        [-4.4172320e-01, -3.1749788e-01],\n",
       "        [ 1.6179664e-01,  5.0522231e-02],\n",
       "        [-8.8870553e-03, -1.6293117e-01],\n",
       "        [ 3.0849010e-01, -2.1301046e-01],\n",
       "        [ 2.0699924e-01, -8.8839509e-02],\n",
       "        [-3.7715772e-01,  2.9507387e-01],\n",
       "        [ 3.7864782e-02, -2.1231069e-01],\n",
       "        [ 3.6539558e-01, -4.7792044e-01],\n",
       "        [ 5.8869056e-02,  3.7497985e-01],\n",
       "        [-2.2743031e-02, -2.8333926e-01],\n",
       "        [ 1.0135282e-01, -2.6681724e-01],\n",
       "        [-3.7904657e-02, -4.7861642e-01],\n",
       "        [ 9.0609631e-03,  2.1880610e-01],\n",
       "        [ 6.2537706e-01, -6.5781075e-01],\n",
       "        [-4.1662413e-01,  2.3690897e-01],\n",
       "        [-1.7999546e-01,  2.2605014e-01],\n",
       "        [-1.4543435e-01, -1.3186857e-01],\n",
       "        [ 2.5877520e-01, -3.5493404e-01],\n",
       "        [-3.5227615e-02,  2.5814554e-01],\n",
       "        [ 2.9453072e-01,  2.9453039e-01]], dtype=float32),\n",
       " array([-0.00039661,  0.0003966 ], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.summary()\n",
    "new_model.get_weights()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "Create a test set and use that to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[0 0]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[0 1]\n",
      "1\n",
      "[0 0]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[0 1]\n",
      "1\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "[1 0]\n",
      "1\n",
      "[1 1]\n",
      "0\n",
      "\r",
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "test_samples = []\n",
    "test_labels = []\n",
    "for i in range(100):\n",
    "    single_list = []\n",
    "    a = randint(0, 1)\n",
    "    b = randint(0, 1)\n",
    "    single_list.append(a)\n",
    "    single_list.append(b)\n",
    "    test_samples.append(single_list)\n",
    "    if a + b == 1: test_labels.append(1)\n",
    "    else: test_labels.append(0)\n",
    "\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "for i in range(100):\n",
    "    print test_samples[i]\n",
    "    print test_labels[i] \n",
    "# test_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# scaled_test_samples = test_scaler.fit_transform((test_samples).reshape(-1, 1))\n",
    "\n",
    "predictions = model.predict(test_samples, verbose=1, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.5450618e-05, 9.9992454e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [9.9962008e-01, 3.7986386e-04],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [7.5450618e-05, 9.9992454e-01],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9993336e-01, 6.6637745e-05],\n",
       "       [2.4237468e-04, 9.9975759e-01],\n",
       "       [9.9993336e-01, 6.6637745e-05]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['no-effect', 'effect']\n",
    "cm = confusion_matrix(test_labels, np.round(predictions[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 0 53]\n",
      " [47  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, cm_plot_labels, title='confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
